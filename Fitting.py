
"""
fitting.py  (Spyder-ready)

Fits Monte Carlo EIS spectra generated by spectra.py 

- Loads dataset from ./results_spectra/spectra_mc.npz
- Uses geometric initial guesses 
- Uses bounds strategy (LB=0, UB=20x init for R/Q; alpha UB=2; L UB=2 µH)
- Uses random multi-start sequence (1, 5, 10) until RMSE < 1e-6
- Reorders Randles elements by time constant to resolve permutation ambiguity 
- Prints summary stats + saves and shows inspection plots

Run in Spyder (F5). Outputs go to ./results_fitting/
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import least_squares
from scipy.signal import find_peaks
from scipy.stats import gaussian_kde
import time


# =========================
# USER SETTINGS
# =========================
DATA_PATH = os.path.join("results_spectra", "spectra_mc.npz")
OUT_DIR = "results_fitting"

RMSE_THRESHOLD = 1e-6
NSTARTS_SEQ = (1, 5, 10)
MAX_NFEV = 5000
METHOD = "trf"

SAVE_RESULTS = True
SAVE_FIGS = True
SHOW_FIGS = True

PLOT_FIT_SUBSET = 15  # number of fitted curves overlaid on Nyquist
HIST_BINS = 30


# =========================
# MODEL 2
# theta = [R0, R1, Q1, a1, R2, Q2, a2, Qw, L]
# =========================
def model2_impedance(freq_hz, theta):
    R0, R1, Q1, a1, R2, Q2, a2, Qw, L = theta
    w = 2.0 * np.pi * freq_hz
    s = 1j * w

    Z_R0 = R0
    Z_L = s * L
    Z_Ra1 = R1 / (1.0 + R1 * Q1 * (s ** a1))
    Z_Ra2 = R2 / (1.0 + R2 * Q2 * (s ** a2))
    Z_w = 1.0 / (Qw * (s ** 0.5))  # Warburg: alpha fixed 0.5

    return Z_R0 + Z_L + Z_Ra1 + Z_Ra2 + Z_w


def residual_real_imag(theta, freqs, Z_meas):
    Z_mod = np.array([model2_impedance(f, theta) for f in freqs], dtype=np.complex128)
    return np.concatenate([(Z_mod.real - Z_meas.real), (Z_mod.imag - Z_meas.imag)])


def rmse_complex(Z_mod, Z_meas):
    return float(np.sqrt(np.mean(np.abs(Z_mod - Z_meas) ** 2)))


# =========================
# Helpers for geometric initialization 
# =========================
def _sorted_by_desc_freq(freqs, Z):
    idx = np.argsort(freqs)[::-1]  # descending
    return freqs[idx], Z[idx], idx


def _local_minima_indices(y, prom):
    # minima of y correspond to peaks of -y
    mins, _ = find_peaks(-y, prominence=prom)
    return mins.astype(int)


def _safe_positive(x, eps=1e-18):
    return float(max(float(x), eps))


def initial_values_model2(freqs, Z):
    """
     geometric initialization :
    - R0, L from highest-frequency point A
    - Randles elements from points A, B, C 
    - Warburg from low-frequency straight line D..E excluding C ,
      then alpha_w capped to 0.5 (Warburg)
    """
    eps = 1e-18

    f, Zs, _ = _sorted_by_desc_freq(freqs, Z)
    x = Zs.real.astype(float)
    y = (-Zs.imag).astype(float)  # Nyquist uses -Im(Z) >= 0

    n = len(f)
    if n < 6:
        raise ValueError("Need at least ~6 frequency points for geometric initialization.")

    # A: highest frequency point
    iA = 0

    # R0, L
    R0_init = max(float(x[iA]), 0.0)
    wA = 2.0 * np.pi * float(f[iA])
    L_init = float(Zs[iA].imag / wA) if Zs[iA].imag > 0 else 0.0
    L_init = max(L_init, 0.0)

    # Identify minima (A,B,C) on y = -Im(Z)
    prom = 0.02 * float(np.max(y)) if np.max(y) > 0 else 1e-12
    mins = _local_minima_indices(y, prom=prom)

    # Always include endpoints as candidates if close to axis
    candidates = set(mins.tolist())
    candidates.add(0)
    candidates.add(n - 1)
    mins = np.array(sorted(candidates), dtype=int)

    # Choose C as the lowest-frequency dip before the Warburg tail (exclude last point)
    if len(mins) >= 2:
        mins_no_last = mins[mins < (n - 1)]
        if len(mins_no_last) == 0:
            mins_no_last = mins
        iC = int(mins_no_last[np.argmin(f[mins_no_last])])  # smallest frequency among minima
    else:
        iC = n - 2

    # Choose B as the next minimum at higher frequency than C (if possible)
    mins_hi = mins[mins < iC]
    if len(mins_hi) >= 1:
        iB = int(mins_hi[np.argmin(f[mins_hi])])  # closest to C but higher freq
    else:
        iB = int(np.argmax(y))  # fallback: top of arc

    # Enforce ordering A < B < C in index space (descending frequency order)
    if not (iA < iB < iC):
        iB = int(np.clip(iB, 1, n - 3))
        iC = int(np.clip(iC, iB + 1, n - 2))
        if not (iA < iB < iC):
            iB = n // 2
            iC = n - 2

    # Determine if inflection point B is "identifiable" 
    identifiable = True
    if (iC - iB) < 2:
        identifiable = False

    # Compute R1, R2 
    R1_init = float(x[iB] - x[iA])
    R2_init = float(x[iC] - x[iB])
    R1_init = max(R1_init, 0.0)
    R2_init = max(R2_init, 0.0)

    # y_max and omega_max 
    w = 2.0 * np.pi * f.astype(float)

    if identifiable:
        seg1 = slice(iA, iB + 1)
        seg2 = slice(iB, iC + 1)

        iP1 = int(np.argmax(y[seg1]) + seg1.start)
        iP2 = int(np.argmax(y[seg2]) + seg2.start)

        y_max1 = float(y[iP1])
        y_max2 = float(y[iP2])

        w_max1 = float(w[iP1])
        w_max2 = float(w[iP2])
    else:
        #  y_max1 = y_max2 = y_max = y(B)/2
        y_max1 = float(0.5 * y[iB])
        y_max2 = float(0.5 * y[iB])
        w_max1 = float(w[iB])
        w_max2 = float(w[iB])

    # alpha with cap at 1
    def alpha_from_arc(Ri, ymi):
        Ri = _safe_positive(Ri, eps=eps)
        val = (4.0 / np.pi) * np.arctan((2.0 * ymi) / Ri)
        return float(val if val <= 1.0 else 1.0)

    a1_init = alpha_from_arc(R1_init, y_max1)
    a2_init = alpha_from_arc(R2_init, y_max2)

    # Q : Qi = 1/(Ri * w_max^alpha)
    def Q_from_arc(Ri, wi, ai):
        Ri = _safe_positive(Ri, eps=eps)
        wi = _safe_positive(wi, eps=eps)
        return float(1.0 / (Ri * (wi ** ai)))

    Q1_init = Q_from_arc(R1_init, w_max1, a1_init)
    Q2_init = Q_from_arc(R2_init, w_max2, a2_init)

    Q1_init = _safe_positive(Q1_init, eps=eps)
    Q2_init = _safe_positive(Q2_init, eps=eps)

    # Warburg initial value via low-frequency straight line D..E excluding C 
    iD = n - 1  # lowest frequency
    iE = max(iC - 1, 2)

    if iE <= iD:
        # If C is too close to the end, use last 4 points
        iE = max(n - 4, 2)

    k0 = min(iD, iE)
    k1 = max(iD, iE)
    ks = np.arange(k0, k1 + 1, dtype=int)

    xD = float(x[iD])

    dx = (x[ks] - xD).astype(float)
    yy = y[ks].astype(float)

    # Fit y = m*(x - xD) (OLS through origin in transformed coordinates)
    denom = float(np.dot(dx, dx))
    if denom <= 0:
        slope = 1.0
    else:
        slope = float(np.dot(dx, yy) / denom)

    #  alpha = (2/pi) * atan(slope), cap to 0.5 (Warburg)
    a_w = float((2.0 / np.pi) * np.arctan(slope))
    if a_w >= 0.5:
        a_w = 0.5

    # Q = ( mean_k [ w_k^(2a) * ((x-xD)^2 + y^2) ] )^(-1/2)
    ww = w[ks].astype(float)
    term = (ww ** (2.0 * a_w)) * (dx * dx + yy * yy)
    mterm = float(np.mean(term)) if term.size > 0 else 1.0
    Qw_init = float(mterm ** (-0.5)) if mterm > 0 else 1.0
    Qw_init = _safe_positive(Qw_init, eps=eps)

    x0 = np.array([R0_init, R1_init, Q1_init, a1_init, R2_init, Q2_init, a2_init, Qw_init, L_init], dtype=float)
    return x0


def bounds_from_initial(x0):
    """
    Paper bounds (Section 3.3):
    - LB = 0 for all
    - UB = 20 * init for R and Q parameters
    - alpha UB = 2
    - L UB = 2 µH
    """
    eps_ub = 1e-12
    lb = np.zeros_like(x0, dtype=float)

    ub = np.zeros_like(x0, dtype=float)

    # R and Q parameter indices: [R0,R1,Q1,R2,Q2,Qw]
    for idx in [0, 1, 2, 4, 5, 7]:
        ub[idx] = max(20.0 * float(x0[idx]), eps_ub)

    # alpha exponents
    ub[3] = 2.0
    ub[6] = 2.0

    # inductance
    ub[8] = 2e-6

    return lb, ub


def reorder_randles_by_tau(theta):
    """
    Resolve Randles permutation ambiguity :
    Order by time constant tau = (R*Q)^(1/alpha).
    If tau1 > tau2, swap (R1,Q1,a1) with (R2,Q2,a2).
    """
    R1, Q1, a1 = float(theta[1]), float(theta[2]), float(theta[3])
    R2, Q2, a2 = float(theta[4]), float(theta[5]), float(theta[6])

    eps = 1e-18
    a1 = max(a1, eps)
    a2 = max(a2, eps)

    tau1 = np.exp((np.log(max(R1, eps)) + np.log(max(Q1, eps))) / a1)
    tau2 = np.exp((np.log(max(R2, eps)) + np.log(max(Q2, eps))) / a2)

    if tau1 > tau2:
        theta = theta.copy()
        theta[1], theta[4] = theta[4], theta[1]
        theta[2], theta[5] = theta[5], theta[2]
        theta[3], theta[6] = theta[6], theta[3]
    return theta


def fit_one_spectrum(freqs, Z_meas, rmse_threshold=RMSE_THRESHOLD, nstarts_seq=NSTARTS_SEQ, seed=None):
    """
    r multi-start procedure :
    Try starts in {1,5,10} until RMSE < threshold, pick best solution.
    """
    rng = np.random.default_rng(seed)

    x0 = initial_values_model2(freqs, Z_meas)
    lb, ub = bounds_from_initial(x0)

    best = None
    best_rmse = np.inf

    for nstarts in nstarts_seq:
        starts = [x0]

        # Random starts within [lb, ub]
        if nstarts > 1:
            for _ in range(nstarts - 1):
                r = rng.uniform(0.0, 1.0, size=len(x0))
                xrand = lb + r * (ub - lb)
                xrand = np.clip(xrand, lb + 1e-15, ub - 1e-15)
                starts.append(xrand)

        for s0 in starts:
            s0 = np.clip(s0, lb + 1e-15, ub - 1e-15)

            res = least_squares(
                residual_real_imag,
                s0,
                args=(freqs, Z_meas),
                bounds=(lb, ub),
                method=METHOD,
                max_nfev=MAX_NFEV,
            )

            if not np.all(np.isfinite(res.x)):
                continue

            Z_fit = np.array([model2_impedance(f, res.x) for f in freqs], dtype=np.complex128)
            r = rmse_complex(Z_fit, Z_meas)

            if r < best_rmse:
                best_rmse = r
                best = res.x

        if best is not None and best_rmse < rmse_threshold:
            break

    if best is None:
        raise RuntimeError("Fitting failed for this spectrum (no finite solution).")

    best = reorder_randles_by_tau(best)
    return best, best_rmse


# =========================
# MAIN
# =========================
def main():
    os.makedirs(OUT_DIR, exist_ok=True)

    # Load dataset
    data = np.load(DATA_PATH, allow_pickle=True)
    freqs = data["freqs"].astype(float)
    Z_true = data["Z_true"].astype(np.complex128)
    Z_noisy = data["Z_noisy"].astype(np.complex128)
    theta_true = data["theta_true"].astype(float)
    sigma = float(data["sigma"])
    seed = int(data["seed"])

    n_spectra, n_freq = Z_noisy.shape
    n_params = len(theta_true)

    print("Loaded dataset:")
    print(" ", DATA_PATH)
    print(f"  N_spectra={n_spectra}, N_freq={n_freq}, N_params={n_params}")
    print(f"  sigma={sigma} (complex), seed={seed}")
    print("  theta_true:", theta_true.tolist())

    # Fit all spectra
    t0 = time.time()
    thetas_hat = np.empty((n_spectra, n_params), dtype=float)
    rmses = np.empty(n_spectra, dtype=float)

    for i in range(n_spectra):
        th, r = fit_one_spectrum(freqs, Z_noisy[i, :], seed=1000 + i)
        thetas_hat[i, :] = th
        rmses[i] = r
        if (i + 1) % 50 == 0:
            print(f"Fitted {i+1}/{n_spectra}   mean RMSE so far: {np.mean(rmses[:i+1]):.3e}")

    dt = time.time() - t0
    print("\nDone.")
    print(f"Total fitting time: {dt:.2f} s   ({1000.0*dt/n_spectra:.2f} ms/spectrum)")
    print(f"RMSE: mean={np.mean(rmses):.3e}, median={np.median(rmses):.3e}, max={np.max(rmses):.3e}")

    # Summary stats
    names = ["R0", "R1", "Q1", "a1", "R2", "Q2", "a2", "Qw", "L"]
    mean_hat = np.mean(thetas_hat, axis=0)
    std_hat = np.std(thetas_hat, axis=0, ddof=1)
    se_hat = std_hat / np.sqrt(n_spectra)

    print("\nParameter estimates (mean ± SE) vs true:")
    for k, nm in enumerate(names):
        print(f"{nm:>3s}:  {mean_hat[k]:.8g} ± {se_hat[k]:.3g}    (true {theta_true[k]:.8g})")

    # Save results
    if SAVE_RESULTS:
        out_npz = os.path.join(OUT_DIR, "fit_results_mc.npz")
        np.savez_compressed(
            out_npz,
            freqs=freqs,
            theta_true=theta_true,
            thetas_hat=thetas_hat,
            rmses=rmses,
            sigma=sigma,
            seed=seed,
        )
        print("\nSaved results:")
        print(" ", out_npz)

    # =========================
    # FIGURE 1: Nyquist overlay (true + one noisy + subset of fits)
    # =========================
    plt.figure(figsize=(7.5, 6))
    plt.plot(Z_true.real, -Z_true.imag, "k-", lw=2.5, label="True")
    plt.scatter(Z_noisy[0, :].real, -Z_noisy[0, :].imag, s=18, alpha=0.7, label="Noisy (example)")

    pick = np.linspace(0, n_spectra - 1, PLOT_FIT_SUBSET, dtype=int)
    for i in pick:
        Z_fit = np.array([model2_impedance(f, thetas_hat[i, :]) for f in freqs], dtype=np.complex128)
        plt.plot(Z_fit.real, -Z_fit.imag, "-", lw=1, alpha=0.6)

    plt.axis("equal")
    plt.grid(True, alpha=0.3)
    plt.xlabel("Re(Z) [Ω]")
    plt.ylabel("-Im(Z) [Ω]")
    plt.title("Model 2: True vs fitted curves (subset)")
    plt.legend()
    plt.tight_layout()

    if SAVE_FIGS:
        fig1 = os.path.join(OUT_DIR, "nyquist_fits_subset.png")
        plt.savefig(fig1, dpi=300)
        print("Saved figure:", fig1)
    if SHOW_FIGS:
        plt.show()
    else:
        plt.close()

    # =========================
    # FIGURE 2: RMSE histogram
    # =========================
    plt.figure(figsize=(7.0, 5.0))
    plt.hist(rmses, bins=40, alpha=0.8)
    plt.grid(True, alpha=0.3)
    plt.xlabel("RMSE (complex)")
    plt.ylabel("Count")
    plt.title("RMSE distribution across Monte Carlo fits")
    plt.tight_layout()

    if SAVE_FIGS:
        fig2 = os.path.join(OUT_DIR, "rmse_hist.png")
        plt.savefig(fig2, dpi=300)
        print("Saved figure:", fig2)
    if SHOW_FIGS:
        plt.show()
    else:
        plt.close()

    # =========================
    # FIGURE 3: Parameter histograms + KDE + true line
    # =========================
    plt.figure(figsize=(12, 9))
    plt.suptitle("Parameter distributions (after τ reordering)", fontsize=14)

    for k in range(n_params):
        plt.subplot(3, 3, k + 1)
        vals = thetas_hat[:, k]
        plt.hist(vals, bins=HIST_BINS, density=True, alpha=0.75)
        try:
            kde = gaussian_kde(vals)
            xs = np.linspace(np.min(vals), np.max(vals), 250)
            plt.plot(xs, kde(xs), lw=2)
        except Exception:
            pass
        plt.axvline(theta_true[k], linestyle="--", linewidth=2)
        plt.title(names[k])
        plt.grid(True, alpha=0.25)

    plt.tight_layout(rect=[0, 0, 1, 0.95])

    if SAVE_FIGS:
        fig3 = os.path.join(OUT_DIR, "params_hist_kde.png")
        plt.savefig(fig3, dpi=300)
        print("Saved figure:", fig3)
    if SHOW_FIGS:
        plt.show()
    else:
        plt.close()


if __name__ == "__main__":
    main()
